N
Over-rewarding
M
##########
#p...#####
#..b.#x#.#
#....#.#.#
#........#
#........#
#........#
##########
I
Training a model is not a straightforward process and sometimes giving too many rewards will lead the robot to not reach the target. In this case, the robot is satisfied with the rewards it gets every time it moves a box. 

Try removing some rules to help the robot push the box on the target. 
[REMOVING RULES? NOT TWEAKING THE REWARDS? WHAT ABOUT USING THE MOVE ONTO EMPTY GROUND EXAMPLE? ALTHOUGH FOR THAT IT MIGHT BE TOO LATE, AS THEY ARE LIKELY TO GET TRAPPED BY THAT IN ONE OF THE DIFFICULT EARLIER LEVELS.

THE CONCEPT WOULD BENEFIT FROM BEING INTRODUCED EARLIER; THIS LEVEL CAN'T REALLY BE SOLVED BY JUST REMOVING RULES, OR REDUCING REWARDS, BUT WITH A DIFFERENT MAP, IT MIGHT WORK AS, SAY, LEVEL 5 I THINK.

ON ITS OWN, AS IT IS, THE LEVEL IS MOSTLY SOLVED WITH THE SAME RULES AS THE PREVIOUS, JUST A LOT MORE GENERATIONS AND HIGHER THRESHOLD. NOT SURE IF THAT'S GOOD.

ACTUALLY, I DO SUSPECT THIS LEVEL SERIOUSLY MORE DIFFICULT BECAUSE OF THE DISTANCE RULES NOT WORKING CORRECTLY (NOT ACCOUNTING FOR WALLS). SAME AS 4, I BELIEVE THIS IS THE REASON I COULDN'T COMPLETE IT.]