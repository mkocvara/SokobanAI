N
Exploration threshold
M
##########
#x.#.#...#
#....#...#
#..b.#...#
###.##...#
#........#
#....#..p#
##########
I
Sometimes, the robot might not perform actions with high reward because it does not know how valuable they are. [EXPLAIN WHY - I.E., THEY HAVEN'T ATTEMPTED AT RANDOM THEM DURING TRAINING]

To help the robot explore more options, we use the EXPLORATION THRESHOLD. If we set it to 100, then the robot will have a high chance of randomly trying actions for 100 games. After these 100 games, the robot will use its knowledge to win the game. 

Try changing the exploration threshold to help the robot win the game. 

[I WOULD HONESTLY EITHER GET RID OF THIS ENTIRELY AND MAKE UP OUR OWN THRESHOLDS FOR EACH LEVEL / CALCULATE THEM AS A FRACTION OF GENERATIONS, OR ALTERNATIVELY MOVE IT AFTER LEVEL 3, WHERE WE EXPLAIN LEARNING. IT LEADS NICELY INTO THIS I RECKON. ALSO, I FIND THE GAME ACTUALLY MORE FUN WITH THE TWEAKABLE EXPLORATION THRESHOLD, AND IT ALSO HELPED ME UNDERSTAND Q-LEARNING BETTER.

AS FOR THE MAP, IT'S PRETTY DECENT FOR EXPLAING EXPLORATION THRESHOLD, BUT I RECKON ONLY IF WE MOVE IT TO THE PLACE I SUGGESTED ABOVE. OTHERWISE, IT DOESN'T NEED ANY HIGHER THRESHOLD THAN LEVELS 4 THROUGH 7.]